{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31dde0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
    "from autogen_core import SingleThreadedAgentRuntime\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "065dbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass \n",
    "class Message:\n",
    "    content : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "408836ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAgent(RoutedAgent):\n",
    "    def __init__(self)->None:\n",
    "        super().__init__(\"Simple\")\n",
    "\n",
    "    @message_handler\n",
    "    async def on_my_message(self, message : Message, ctx: MessageContext) -> Message:\n",
    "        return Message(content = f\"This is {self.id.type}-{self.id.key}. You said '{message.content}' and I disagee.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb38e28",
   "metadata": {},
   "source": [
    "Creating a Single Threaded Standalone Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ce7a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='simple_agent')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf93f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7b3e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> This is simple_agent-default. You said 'Well, hi there!' and I disagee.\n"
     ]
    }
   ],
   "source": [
    "agent_id = AgentId(\"simple_agent\", \"default\")\n",
    "response = await runtime.send_message(Message(\"Well, hi there!\"), agent_id)\n",
    "print(\">>>\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6726597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6074bc",
   "metadata": {},
   "source": [
    "Using AgentChat Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "036a32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLLMAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"LLMAgent\")\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(\"LLMAgent\", model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        print(f\"{self.id.type} received message: {message.content}\")\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        reply = response.chat_message.content\n",
    "        print(f\"{self.id.type} responded: {reply}\")\n",
    "        return Message(content=reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3ab2463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='LLMAgent')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_core import SingleThreadedAgentRuntime\n",
    "\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())\n",
    "await MyLLMAgent.register(runtime, \"LLMAgent\", lambda: MyLLMAgent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9afa99f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMAgent received message: Hi there!\n",
      "LLMAgent responded: Hello! How can I assist you today?\n",
      ">>> Hello! How can I assist you today?\n",
      ">>> This is simple_agent-default. You said 'Hello! How can I assist you today?' and I disagee.\n",
      "LLMAgent received message: This is simple_agent-default. You said 'Hello! How can I assist you today?' and I disagee.\n",
      "LLMAgent responded: I appreciate your feedback! How can I better assist you today?\n"
     ]
    }
   ],
   "source": [
    "runtime.start()\n",
    "response = await runtime.send_message(Message(\"Hi there!\"), AgentId(\"LLMAgent\", \"default\"))\n",
    "print(\">>>\", response.content)\n",
    "response = await runtime.send_message(Message(response.content), AgentId(\"simple_agent\", \"default\"))\n",
    "print(\">>>\", response.content)\n",
    "response = await runtime.send_message(Message(response.content), AgentId(\"LLMAgent\", \"default\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5141c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3a960",
   "metadata": {},
   "source": [
    "Create Rock Paper Scissor with three Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f939be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self, name:str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model = \"gpt-4o-mini\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "    \n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message : Message, ctx : MessageContext) -> Message:\n",
    "        text_message = TextMessage(content = message.content, source = \"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model = \"gpt-4\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "    \n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content = message.content, source = \"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cfcfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE = \"You are jusging a game of Rock, Paper and Scissors. The players have made these choices: \\n\"\n",
    "\n",
    "class RockPaperScissorAgent(RoutedAgent):\n",
    "    def __init__(self, name : str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model = \"gpt-4o-mini\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client = model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message : Message, ctx : MessageContext) -> Message:\n",
    "        instruction = \"You are playing Rock, Paper and Scissors. Respond with only one word out of : Rock, Paper and Scissor\"\n",
    "        message = Message(content=instruction)\n",
    "        inner1 = AgentId(\"player1\", \"default\")\n",
    "        inner2 = AgentId(\"player2\", \"default\")\n",
    "        response1 = await self.send_message(message, inner1)\n",
    "        response2 = await self.send_message(message, inner2)\n",
    "        result = f\"Player 1 : {response1.content}\\n Player 2 : {response2.content}\\n\"\n",
    "        judgement = f\"{JUDGE}{result} Who wins?\"\n",
    "        message = TextMessage(content = judgement, source = \"user\")\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3183ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "await Player1Agent.register(runtime, \"player1\", lambda : Player1Agent(\"player1\"))\n",
    "await Player2Agent.register(runtime, \"player2\", lambda : Player2Agent(\"player2\"))\n",
    "await RockPaperScissorAgent.register(runtime, \"rock_paper_scissors\", lambda : RockPaperScissorAgent(\"rock_paper_scissors\"))\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc57c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1 : Rock\n",
      " Player 2 : Paper\n",
      "Player 2 wins as Paper covers Rock. TERMINATE\n"
     ]
    }
   ],
   "source": [
    "agent_id = AgentId(\"rock_paper_scissors\", \"default\")\n",
    "message = Message(content = \"go\")\n",
    "response = await runtime.send_message(message, agent_id)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "833f8a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d896cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
