{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db049847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "ALL_IN_ONE_WORKER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ccace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f121ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntimeHost\n",
    "\n",
    "host = GrpcWorkerAgentRuntimeHost(address = \"localhost:50051\")\n",
    "host.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d46f7ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "serper = GoogleSerperAPIWrapper()\n",
    "langchain_serper = Tool(name = \"internet_search\", func = serper.run, description=\"Useful when you need to search the internet\")\n",
    "autogen_serper = LangChainToolAdapter(langchain_serper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c3d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction1 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons in favor of choosing AutoGen; the pros of AutoGen.\"\n",
    "\n",
    "instruction2 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons in favor of choosing AutoGen; the cons of AutoGen.\"\n",
    "\n",
    "judge = \"You must make a decision on whether to use AutoGen for a project. \\\n",
    "Your research team has come up with the following reasons for and against. \\\n",
    "Based purely on the research from your team, please respond with your decision and brief rationale.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d78a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Judge(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "        \n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        message1 = Message(content=instruction1)\n",
    "        message2 = Message(content=instruction2)\n",
    "        inner_1 = AgentId(\"player1\", \"default\")\n",
    "        inner_2 = AgentId(\"player2\", \"default\")\n",
    "        response1 = await self.send_message(message1, inner_1)\n",
    "        response2 = await self.send_message(message2, inner_2)\n",
    "        result = f\"## Pros of AutoGen:\\n{response1.content}\\n\\n## Cons of AutoGen:\\n{response2.content}\\n\\n\"\n",
    "        judgement = f\"{judge}\\n{result}Respond with your decision and brief explanation\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + \"\\n\\n## Decision:\\n\\n\" + response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4d54479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntime\n",
    "\n",
    "if ALL_IN_ONE_WORKER:\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "\n",
    "    await Player1Agent.register(worker, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "    await Player2Agent.register(worker, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "\n",
    "    agent_id = AgentId(\"judge\", \"default\")\n",
    "\n",
    "else:\n",
    "\n",
    "    worker1 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker1.start()\n",
    "    await Player1Agent.register(worker1, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "\n",
    "    worker2 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker2.start()\n",
    "    await Player2Agent.register(worker2, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "    agent_id = AgentId(\"judge\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2529bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await worker.send_message(Message(content=\"Go\"), agent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e11edf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Pros of AutoGen:\n",
       "Here are some compelling reasons to choose AutoGen for your AI Agent project:\n",
       "\n",
       "1. **Multi-Agent Collaboration**: AutoGen is specifically designed for scenarios where multiple AI agents work together. This makes it ideal for complex tasks that require collaborative decision-making and interaction.\n",
       "\n",
       "2. **Simplified Development**: It allows engineers to create task-oriented agents without starting from scratch, reducing the time and effort required to develop AI applications.\n",
       "\n",
       "3. **Customizable Agents**: With AutoGen, you can define multiple agents with specific roles and capabilities, tailoring the system to suit the needs of your project.\n",
       "\n",
       "4. **Effective Communication**: The framework uses natural language for inter-agent communication, which simplifies coordination and reduces complexity compared to traditional methods.\n",
       "\n",
       "5. **Robust Backing**: Developed by Microsoft Research, AutoGen benefits from strong support and frequent usage in various applications, providing confidence in its reliability and performance.\n",
       "\n",
       "6. **Open Source**: Being an open-source framework, it allows developers to access and modify the code, fostering community collaboration and innovation.\n",
       "\n",
       "7. **No Revenue Pressure**: As a project funded by Microsoft, AutoGen does not face the same revenue pressures as commercial solutions, allowing it to focus on providing innovative features.\n",
       "\n",
       "8. **Enterprise Ready**: Its capabilities are well-suited for enterprise AI development, enabling the orchestration, optimization, and automation of complex workflows.\n",
       "\n",
       "These advantages make AutoGen a promising choice for building effective AI Agent systems. \n",
       "\n",
       "TERMINATE\n",
       "\n",
       "## Cons of AutoGen:\n",
       "### Reasons in Favor of Choosing AutoGen:\n",
       "1. **Multi-Agent Collaboration**: AutoGen excels in scenarios requiring dynamic collaboration among multiple AI agents, making it ideal for complex tasks involving decision-making and research.\n",
       "2. **Robust Tool Integration**: It offers strong capabilities for integrating with various tools, APIs, and custom functions, allowing agents to perform complex tasks autonomously and interact seamlessly with external resources.\n",
       "3. **Flexibility and Customization**: AutoGen allows for high customization of agents and automation processes, providing fine-grained control over functionalities.\n",
       "4. **Compatibility with Different LLMs**: The framework supports various large language models (LLMs), enabling the development of versatile applications.\n",
       "5. **Strong Backing by Microsoft**: As a Microsoft framework, AutoGen benefits from substantial resources, leading to ongoing improvements and a broad usage base.\n",
       "\n",
       "### Cons of AutoGen:\n",
       "1. **Limited Custom Integrations**: AutoGen can be less flexible when it comes to highly complex or unstructured interactions between agents, which may restrict its usage in some innovative applications.\n",
       "2. **Steeper Learning Curve**: Its open-source nature and focus on developer-centric customization mean it can be more challenging to learn, particularly for non-technical users. Lack of a visual builder or no-code options can make initial development more difficult.\n",
       "3. **Potential for Conversation Issues**: User experiences indicate that multi-agent interactions can sometimes derail, requiring careful management of agent communication and protocols.\n",
       "4. **Less Suitable for Simple Workflows**: If a project involves straightforward, well-defined tasks, other frameworks might offer better performance due to AutoGen's complexity.\n",
       "\n",
       "TERMINATE\n",
       "\n",
       "\n",
       "\n",
       "## Decision:\n",
       "\n",
       "Based on the pros and cons presented, I recommend using AutoGen for the project. The strengths of AutoGen, such as its capabilities for multi-agent collaboration, simplified development process, customization options, effective communication, and strong backing from Microsoft Research, align well with the needs of complex AI Agent applications. \n",
       "\n",
       "While there are some drawbacks, such as the steeper learning curve and potential conversation issues, these can be managed with a capable development team. The advantages greatly outweigh the cons, particularly for projects involving intricate workflows and collaborative tasks, making AutoGen a promising and suitable choice.\n",
       "\n",
       "TERMINATE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24086d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "await worker.stop()\n",
    "if not ALL_IN_ONE_WORKER:\n",
    "    await worker1.stop()\n",
    "    await worker2.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d0bab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "await host.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba8d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
